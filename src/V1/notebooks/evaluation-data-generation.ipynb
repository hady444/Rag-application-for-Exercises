{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f35b1666-5393-458a-b747-177c1a1525ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a88433ad-dcc1-4455-a0df-3006b43c52a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"ollama\", base_url=\"http://localhost:11434/api/generate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5babe3a1-3d8b-428a-92a8-5fc2285fc494",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/my_data.csv')\n",
    "documents = df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0d9752d8-ab2f-48d4-a3d9-fa33edb52c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You emulate a user of our fitness assistant application.\n",
    "Formulate 5 questions this user might ask based on a provided exercise.\n",
    "Make the questions specific to this exercise.\n",
    "The record should contain the answer to the questions, and the questions should\n",
    "be complete and not too short. Use as fewer words as possible from the record. \n",
    "\n",
    "The record:\n",
    "\n",
    "\"name\": {name},\n",
    "\"category\": {category},\n",
    "\"equipment\": {equipment},\n",
    "\"force\": {force},\n",
    "\"instructions\": {instructions},\n",
    "\"level\": {level},\n",
    "\"mechanic\": {mechanic},\n",
    "\"primaryMuscles\": {primaryMuscles},\n",
    "\"secondaryMuscles\": {secondaryMuscles}\n",
    "\n",
    "Provide the output in parsable JSON without using code blocks:\n",
    "\n",
    "{{\"questions\": [\"question1\", \"question2\", ..., \"question5\"]}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f07f48f9-d611-4a47-bd62-f75731608ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.format(**documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "de2a1632-4d02-46ff-9ae1-58c9704404b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt, max_retries=3):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            url = \"http://localhost:11434/api/generate\"\n",
    "            data = {\n",
    "                \"model\": \"llama3.2:latest\",\n",
    "                \"prompt\": prompt,\n",
    "                \"stream\": False,\n",
    "                # Optional parameters\n",
    "                \"temperature\": 0.7,\n",
    "                \"top_p\": 0.9,\n",
    "                \"max_tokens\": 500\n",
    "            }\n",
    "            \n",
    "            response = requests.post(url, json=data, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            return response.json()['response']\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "            if attempt == max_retries - 1:\n",
    "                return \"Error: Unable to get response from LLM\"\n",
    "            \n",
    "            import time\n",
    "            time.sleep(1)  # Wait before retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6534a160-f763-4d21-8176-4bed6326bbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f7619d05-0e93-4418-bb8e-313eeab8ac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd42bff8-dfa3-49af-82c9-bcb5c0e8ce3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "da0d6db9-9ed8-48a6-b483-ead8786a5fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(doc):\n",
    "    # Format the prompt\n",
    "    prompt = prompt_template.format(**doc)\n",
    "\n",
    "    # Define the Ollama API endpoint and parameters\n",
    "    url = \"http://localhost:11434/api/generate\"  # Ollama's local API endpoint\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o-mini\",  # Specify the Ollama model\n",
    "        \"prompt\": prompt\n",
    "    }\n",
    "\n",
    "    # Make a request to Ollama's API\n",
    "    response = requests.post(url, json=payload)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Parse the JSON response to get the content\n",
    "        json_response = response.json()[\"content\"]\n",
    "        return json_response\n",
    "    else:\n",
    "        # Handle errors\n",
    "        raise Exception(f\"Error {response.status_code}: {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d95afcdc-9382-4d75-b0e3-3e7cd72feba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9eed0e63-1e1d-449a-89e2-d6c3a8af60ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6420880-03d7-4366-9243-7a4add719f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in tqdm(documents):\n",
    "    doc_id = doc['id']\n",
    "    \n",
    "    # Skip if results already contain this document ID\n",
    "    if doc_id in results:\n",
    "        continue\n",
    "\n",
    "    # Generate questions for the document\n",
    "    try:\n",
    "        questions_raw = generate_questions(doc)\n",
    "        print(questions_raw)\n",
    "        \n",
    "        # Parse and store the generated questions\n",
    "        results[doc_id] = questions_raw  # Assuming `questions_raw` is already structured appropriately\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing document {doc_id}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2bcc6347-80af-499e-9ee6-d346f0e9f067",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = []\n",
    "\n",
    "for doc_id, questions in results.items():\n",
    "    for q in questions:\n",
    "        final_results.append((doc_id, q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0037e60a-e338-481e-9845-e3161c881ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3e1fac17-dccb-46d7-bade-50166dafbd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(final_results, columns=['id', 'question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c64131b0-9cca-488b-a819-320bcd5f9342",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv('../data/ground-truth-retrieval.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4e5a91-a049-432d-b5f4-cc4320c27a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head ../data/ground-truth-retrieval.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f87a34-e06b-4393-95ff-4d587c09afd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
